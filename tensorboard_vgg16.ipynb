{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (Epoch 1): 3.5034\n",
      "Train Accuracy (Epoch 1): 55.6250%\n",
      "Test Loss (Epoch 1): 0.3180\n",
      "Test Accuracy (Epoch 1): 87.5000%\n",
      "Train Loss (Epoch 2): 0.3213\n",
      "Train Accuracy (Epoch 2): 89.3750%\n",
      "Test Loss (Epoch 2): 0.0491\n",
      "Test Accuracy (Epoch 2): 97.5000%\n",
      "Train Loss (Epoch 3): 0.0052\n",
      "Train Accuracy (Epoch 3): 96.8750%\n",
      "Test Loss (Epoch 3): 0.0044\n",
      "Test Accuracy (Epoch 3): 100.0000%\n",
      "Train Loss (Epoch 4): 0.4030\n",
      "Train Accuracy (Epoch 4): 98.7500%\n",
      "Test Loss (Epoch 4): 0.0085\n",
      "Test Accuracy (Epoch 4): 100.0000%\n",
      "Train Loss (Epoch 5): 0.0001\n",
      "Train Accuracy (Epoch 5): 99.3750%\n",
      "Test Loss (Epoch 5): 0.0025\n",
      "Test Accuracy (Epoch 5): 100.0000%\n",
      "Train Loss (Epoch 6): 0.0002\n",
      "Train Accuracy (Epoch 6): 100.0000%\n",
      "Test Loss (Epoch 6): 0.0015\n",
      "Test Accuracy (Epoch 6): 100.0000%\n",
      "Train Loss (Epoch 7): 0.0004\n",
      "Train Accuracy (Epoch 7): 100.0000%\n",
      "Test Loss (Epoch 7): 0.0010\n",
      "Test Accuracy (Epoch 7): 100.0000%\n",
      "Train Loss (Epoch 8): 0.0001\n",
      "Train Accuracy (Epoch 8): 100.0000%\n",
      "Test Loss (Epoch 8): 0.0007\n",
      "Test Accuracy (Epoch 8): 100.0000%\n",
      "Train Loss (Epoch 9): 0.0009\n",
      "Train Accuracy (Epoch 9): 100.0000%\n",
      "Test Loss (Epoch 9): 0.0005\n",
      "Test Accuracy (Epoch 9): 100.0000%\n",
      "Train Loss (Epoch 10): 0.0000\n",
      "Train Accuracy (Epoch 10): 100.0000%\n",
      "Test Loss (Epoch 10): 0.0004\n",
      "Test Accuracy (Epoch 10): 100.0000%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import BinaryCrossentropy\n",
    "# from keras.metrics import Accuracy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "logdir = \"logs\"\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def image_grid():\n",
    "    \"\"\"Return a 4x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "    # Create a figure to contain the plot.\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(20):\n",
    "        test=np.reshape(test_it[0][0][i], (-1, 224, 224, 3))\n",
    "        if model.predict(test)>0.5:\n",
    "            tle='squirrel'\n",
    "        else:\n",
    "            tle='rabbit'\n",
    "        plt.subplot(4, 5, i + 1, title=tle)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow((test_it[0][0][i])/100)\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# specify imagenet mean values for centering\n",
    "datagen.mean = [123.68, 116.779, 103.939]\n",
    "# prepare iterator\n",
    "train_it = datagen.flow_from_directory('images/train/',\n",
    "class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "test_it = datagen.flow_from_directory('images/test/',\n",
    "class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # # compile model\n",
    "    # opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    # model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "num_epochs = 10\n",
    "binary_crossentropy = BinaryCrossentropy()\n",
    "optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "# accuracy_metric = Accuracy()\n",
    "accuracy_metric = BinaryAccuracy()\n",
    "train_writer = tf.summary.create_file_writer(\"logs/train\")\n",
    "test_writer = tf.summary.create_file_writer(\"logs/test\")\n",
    "train_step = test_step = 0\n",
    "\n",
    "batch_size=64\n",
    "num_train_images=160 # for both classes\n",
    "num_test_images=40 # for both classes\n",
    "\n",
    "train_loop_iter=numpy.ceil(num_train_images/batch_size)\n",
    "test_loop_iter=numpy.ceil(num_test_images/batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Iterate through training set\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_it):\n",
    "        # print(f\"Batch {batch_idx}: x shape = {x.shape}, y shape = {y.shape}\")\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training=True)\n",
    "            loss = binary_crossentropy(y, y_pred)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        accuracy_metric.update_state(y, y_pred)\n",
    "\n",
    "        with train_writer.as_default():\n",
    "            tf.summary.scalar(\"Train Loss\", loss, step=train_step)\n",
    "            tf.summary.scalar(\n",
    "                \"Train Accuracy\", accuracy_metric.result().numpy(), step=train_step,\n",
    "            )\n",
    "            train_step += 1\n",
    "\n",
    "        train_loop_iter=train_loop_iter-1\n",
    "        if train_loop_iter==0:\n",
    "            train_loop_iter=numpy.ceil(num_train_images/batch_size)\n",
    "            break\n",
    "    train_writer.flush()\n",
    "    print(f\"Train Loss (Epoch {epoch + 1}): {loss.numpy():.4f}\")\n",
    "    print(f\"Train Accuracy (Epoch {epoch + 1}): {accuracy_metric.result().numpy()*100:.4f}%\")\n",
    "\n",
    "    # Reset accuracy in between epochs (and for testing and test)\n",
    "    accuracy_metric.reset_state()\n",
    "\n",
    "    # Iterate through test set\n",
    "    for batch_idx, (x, y) in enumerate(test_it):\n",
    "        y_pred = model(x, training=False)\n",
    "        loss = binary_crossentropy(y, y_pred)\n",
    "        accuracy_metric.update_state(y, y_pred)\n",
    "\n",
    "        with test_writer.as_default():\n",
    "            tf.summary.scalar(\"Test Loss\", loss, step=test_step)\n",
    "            tf.summary.scalar(\n",
    "                \"Test Accuracy\", accuracy_metric.result().numpy(), step=test_step,\n",
    "            )\n",
    "            test_step += 1\n",
    "\n",
    "        test_loop_iter=test_loop_iter-1\n",
    "        if test_loop_iter==0:\n",
    "            test_loop_iter=numpy.ceil(num_test_images/batch_size)\n",
    "            break\n",
    "    test_writer.flush()\n",
    "    print(f\"Test Loss (Epoch {epoch + 1}): {loss.numpy():.4f}\")\n",
    "    print(f\"Test Accuracy (Epoch {epoch + 1}): {accuracy_metric.result().numpy()*100:.4f}%\")\n",
    "\n",
    "    accuracy_metric.reset_state()\n",
    "\n",
    "# Prepare the plot\n",
    "figure = image_grid()\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Test data\", plot_to_image(figure), step=0)\n",
    "file_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19424), started 13:07:15 ago. (Use '!kill 19424' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-58e0cd8e87f59e70\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-58e0cd8e87f59e70\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
